# 对抗样本
## 描述
使用梯度优化的方法生成对抗样本绕过大模型防护
## 示例
![](../assets/adversarial4.png)
## 参考
- [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)
- [AUTODAN: INTERPRETABLE GRADIENT-BASED ADVERSARIAL ATTACKS ON LARGE LANGUAGE MODELS](https://arxiv.org/abs/2310.15140)
- [From Noise to Clarity: Unraveling the Adversarial Suffix of Large Language Model Attacks via Translation of Text Embeddings](https://arxiv.org/abs/2402.16006v1)
